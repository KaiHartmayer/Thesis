{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7945630,"sourceType":"datasetVersion","datasetId":4671976},{"sourceId":8118178,"sourceType":"datasetVersion","datasetId":4796642},{"sourceId":8118315,"sourceType":"datasetVersion","datasetId":4796733},{"sourceId":8118422,"sourceType":"datasetVersion","datasetId":4796819},{"sourceId":8164346,"sourceType":"datasetVersion","datasetId":4830846},{"sourceId":8165196,"sourceType":"datasetVersion","datasetId":4831085}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-13T10:20:56.007064Z","iopub.execute_input":"2024-05-13T10:20:56.007909Z","iopub.status.idle":"2024-05-13T10:20:56.012533Z","shell.execute_reply.started":"2024-05-13T10:20:56.007873Z","shell.execute_reply":"2024-05-13T10:20:56.011148Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/li-ion/english_li_ion_patents.csv')\ndf['Year'] = pd.to_datetime(df['Application.Date']).dt.year\n\ndf.dtypes","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:53:50.626565Z","iopub.execute_input":"2024-05-13T10:53:50.627379Z","iopub.status.idle":"2024-05-13T10:53:55.494687Z","shell.execute_reply.started":"2024-05-13T10:53:50.627344Z","shell.execute_reply":"2024-05-13T10:53:55.493499Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"Unnamed: 0                       int64\nApplication.Date                object\nCountry.Code                    object\nProbable.Patent.Assignee        object\nFamily.Number                    int64\nTitle                           object\nPriority.Dates                  object\nAbstract                        object\nClaims                          object\nNumber.of.Forward.Citations      int64\nCooperative.Patent.Class        object\nGrant                           object\nAbstract.Languages              object\nClaims.Languages                object\nTitle.Languages                 object\nYear                           float64\ndtype: object"},"metadata":{}}]},{"cell_type":"code","source":"print(df['Country.Code'].value_counts())\n\n# Number of patents in different years\nbins = [1920, 1991, 2009, 2017, 2024]\nlabels = ['1920-1990', '1991-2008', '2009-2016', '2017-2023']\ndf['Year.Range'] = pd.cut(df['Year'], bins=bins, labels=labels)\nprint(df['Year.Range'].value_counts())\n\n# Top 10 Probable.Patent.Assignees\nprint(df['Probable.Patent.Assignee'].value_counts().nlargest(10))\n\n# Distribution of Grant\nprint(df['Grant'].value_counts())\n\n# Number of forward citations\nprint(df['Number.of.Forward.Citations'].describe())\n","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:21:05.324091Z","iopub.execute_input":"2024-05-13T10:21:05.324496Z","iopub.status.idle":"2024-05-13T10:21:05.370837Z","shell.execute_reply.started":"2024-05-13T10:21:05.324464Z","shell.execute_reply":"2024-05-13T10:21:05.369773Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Country.Code\nUS    37031\nEP    10743\nWO     3242\nCA     2365\nIN     2182\nAU      821\nGB      445\nFR       69\nKR       61\nDE       20\nSG       16\nIL       14\nNZ       13\nSE       13\nZA        6\nFI        5\nPH        3\nIE        2\nMY        1\nName: count, dtype: int64\nYear.Range\n2009-2016    23729\n2017-2023    19857\n1991-2008    12188\n1920-1990     1276\nName: count, dtype: int64\nProbable.Patent.Assignee\nLG ENERGY SOLUTION LTD                 7358\nSAMSUNG SDI CO LTD                     4125\nTOYOTA JIDOSHA KK                      1449\nROBERT BOSCH GMBH                      1395\nSANYO ELECTRIC CO LTD                   978\nGM GLOBAL TECHNOLOGY OPERATIONS LLC     960\nSAMSUNG ELECTRONICS CO LTD              864\nSK INNOVATION CO LTD                    595\nLG CHEMICAL LTD                         582\nMURATA MFG CO LTD                       562\nName: count, dtype: int64\nGrant\nNO     40315\nYES    16737\nName: count, dtype: int64\ncount    57052.000000\nmean         7.886665\nstd         32.681977\nmin          0.000000\n25%          0.000000\n50%          1.000000\n75%          6.000000\nmax       1710.000000\nName: Number.of.Forward.Citations, dtype: float64\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\n\n# Define the columns to plot\ncolumns_to_plot = ['Country.Code', 'Probable.Patent.Assignee', 'Family.Number']\n\nfor column in columns_to_plot:\n    # Get the value counts\n    value_counts = df[column].value_counts()\n    \n    # Keep the top 10 values and replace the rest with 'Other'\n    to_keep = value_counts[:10].index\n    df.loc[~df[column].isin(to_keep), column] = 'Other'\n    \n    # Recalculate the value counts\n    value_counts = df[column].value_counts()\n    print(value_counts)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:21:05.373366Z","iopub.execute_input":"2024-05-13T10:21:05.373735Z","iopub.status.idle":"2024-05-13T10:21:05.420099Z","shell.execute_reply.started":"2024-05-13T10:21:05.373706Z","shell.execute_reply":"2024-05-13T10:21:05.418914Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Country.Code\nUS       37031\nEP       10743\nWO        3242\nCA        2365\nIN        2182\nAU         821\nGB         445\nOther       73\nFR          69\nKR          61\nDE          20\nName: count, dtype: int64\nProbable.Patent.Assignee\nOther                                  38184\nLG ENERGY SOLUTION LTD                  7358\nSAMSUNG SDI CO LTD                      4125\nTOYOTA JIDOSHA KK                       1449\nROBERT BOSCH GMBH                       1395\nSANYO ELECTRIC CO LTD                    978\nGM GLOBAL TECHNOLOGY OPERATIONS LLC      960\nSAMSUNG ELECTRONICS CO LTD               864\nSK INNOVATION CO LTD                     595\nLG CHEMICAL LTD                          582\nMURATA MFG CO LTD                        562\nName: count, dtype: int64\nFamily.Number\nOther       55739\n63792182      231\n52192840      191\n51065154      164\n28276411      159\n63834380      144\n82712726       98\n57713258       94\n71449429       89\n43652113       81\n53424874       62\nName: count, dtype: int64\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/2529383101.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Other' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n  df.loc[~df[column].isin(to_keep), column] = 'Other'\n","output_type":"stream"}]},{"cell_type":"code","source":"df['Grant'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:21:05.421328Z","iopub.execute_input":"2024-05-13T10:21:05.421648Z","iopub.status.idle":"2024-05-13T10:21:05.433407Z","shell.execute_reply.started":"2024-05-13T10:21:05.421613Z","shell.execute_reply":"2024-05-13T10:21:05.432195Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"Grant\nNO     40315\nYES    16737\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/df-lemma-clean/df_lemma_dropped.csv')\ndf.head(2)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:21:05.435213Z","iopub.execute_input":"2024-05-13T10:21:05.435720Z","iopub.status.idle":"2024-05-13T10:21:19.362376Z","shell.execute_reply.started":"2024-05-13T10:21:05.435681Z","shell.execute_reply":"2024-05-13T10:21:19.361314Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"  Application.Date Country.Code Probable.Patent.Assignee  Family.Number  \\\n0       2014-02-06           AU    ENCELL TECHNOLOGY INC       57136128   \n1       2014-02-06           AU    ENCELL TECHNOLOGY INC       57136128   \n\n                                               Title  \\\n0  [EN] BATTERY COMPRISING A COATED IRON ANODE AN...   \n1  [EN] BATTERY COMPRISING A COATED IRON ANODE AN...   \n\n   Number.of.Forward.Citations Grant    Year  \\\n0                            0    NO  2014.0   \n1                            0   YES  2014.0   \n\n                                                Text    A    B    C    D    E  \\\n0   BATTERY COMPRISING A COATED IRON ANODE AND IM...  0.0  0.0  0.0  0.0  0.0   \n1   BATTERY COMPRISING A COATED IRON ANODE AND IM...  0.0  0.0  0.0  0.0  0.0   \n\n     F    G    H    Y                                         Text_Lemma  \\\n0  0.0  0.0  1.0  1.0  ['iron', 'anode', 'performance', 'invention', ...   \n1  0.0  0.0  1.0  1.0  ['iron', 'anode', 'performance', 'invention', ...   \n\n                                   Text_Lemma_unlist  \n0  iron anode performance invention iron anode ni...  \n1  iron anode performance invention iron anode ni...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Application.Date</th>\n      <th>Country.Code</th>\n      <th>Probable.Patent.Assignee</th>\n      <th>Family.Number</th>\n      <th>Title</th>\n      <th>Number.of.Forward.Citations</th>\n      <th>Grant</th>\n      <th>Year</th>\n      <th>Text</th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n      <th>D</th>\n      <th>E</th>\n      <th>F</th>\n      <th>G</th>\n      <th>H</th>\n      <th>Y</th>\n      <th>Text_Lemma</th>\n      <th>Text_Lemma_unlist</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2014-02-06</td>\n      <td>AU</td>\n      <td>ENCELL TECHNOLOGY INC</td>\n      <td>57136128</td>\n      <td>[EN] BATTERY COMPRISING A COATED IRON ANODE AN...</td>\n      <td>0</td>\n      <td>NO</td>\n      <td>2014.0</td>\n      <td>BATTERY COMPRISING A COATED IRON ANODE AND IM...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>['iron', 'anode', 'performance', 'invention', ...</td>\n      <td>iron anode performance invention iron anode ni...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2014-02-06</td>\n      <td>AU</td>\n      <td>ENCELL TECHNOLOGY INC</td>\n      <td>57136128</td>\n      <td>[EN] BATTERY COMPRISING A COATED IRON ANODE AN...</td>\n      <td>0</td>\n      <td>YES</td>\n      <td>2014.0</td>\n      <td>BATTERY COMPRISING A COATED IRON ANODE AND IM...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>['iron', 'anode', 'performance', 'invention', ...</td>\n      <td>iron anode performance invention iron anode ni...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Assuming df is your DataFrame\ndf['Text_word_count'] = df['Text'].apply(lambda x: len(str(x).split()))\ndf['Text_Lemma_word_count'] = df['Text_Lemma_unlist'].apply(lambda x: len(str(x).split()))\n\n# Calculate mean, SD, and median for Text\nmean_text = df['Text_word_count'].mean()\nsd_text = df['Text_word_count'].std()\nmedian_text = df['Text_word_count'].median()\n\n# Calculate mean, SD, and median for Text_Lemma_unlist\nmean_lemma = df['Text_Lemma_word_count'].mean()\nsd_lemma = df['Text_Lemma_word_count'].std()\nmedian_lemma = df['Text_Lemma_word_count'].median()\n\nprint(f\"Text: Mean = {mean_text}, SD = {sd_text}, Median = {median_text}\")\nprint(f\"Text_Lemma_unlist: Mean = {mean_lemma}, SD = {sd_lemma}, Median = {median_lemma}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:21:19.363536Z","iopub.execute_input":"2024-05-13T10:21:19.363828Z","iopub.status.idle":"2024-05-13T10:21:22.982534Z","shell.execute_reply.started":"2024-05-13T10:21:19.363804Z","shell.execute_reply":"2024-05-13T10:21:22.981380Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Text: Mean = 929.1571050463621, SD = 581.5042667514032, Median = 796.0\nText_Lemma_unlist: Mean = 234.9654694922087, SD = 156.24849003862303, Median = 197.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# Assuming df is your DataFrame\ndf['Text_word_count'] = df['Text'].apply(lambda x: len(str(x).split()))\ndf['Text_Lemma_word_count'] = df['Text_Lemma_unlist'].apply(lambda x: len(str(x).split()))\n\ntime_periods = [(min(df['Year']), 1990), (1991, 2008), (2009, 2016), (2017, max(df['Year']))]\n\nfor start, end in time_periods:\n    df_period = df[df['Year'].between(start, end)]\n    \n    mean_text = df_period['Text_word_count'].mean()\n    sd_text = df_period['Text_word_count'].std()\n    median_text = df_period['Text_word_count'].median()\n\n    mean_lemma = df_period['Text_Lemma_word_count'].mean()\n    sd_lemma = df_period['Text_Lemma_word_count'].std()\n    median_lemma = df_period['Text_Lemma_word_count'].median()\n    \n    mean_citations = df_period['Number.of.Forward.Citations'].mean()\n    sd_citations = df_period['Number.of.Forward.Citations'].std()\n    median_citations = df_period['Number.of.Forward.Citations'].median()\n\n    print(f\"Time period: {start} - {end}\")\n    print(f\"Number.of.Forward.Citations: Mean = {mean_citations}, SD = {sd_citations}, Median = {median_citations}\")\n    print(f\"Text: Mean = {mean_text}, SD = {sd_text}, Median = {median_text}\")\n    print(f\"Text_Lemma_unlist: Mean = {mean_lemma}, SD = {sd_lemma}, Median = {median_lemma}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:21:22.984010Z","iopub.execute_input":"2024-05-13T10:21:22.984453Z","iopub.status.idle":"2024-05-13T10:21:26.590465Z","shell.execute_reply.started":"2024-05-13T10:21:22.984412Z","shell.execute_reply":"2024-05-13T10:21:26.589250Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Time period: 1920.0 - 1990\nNumber.of.Forward.Citations: Mean = 18.63330457290768, SD = 45.35295427558024, Median = 6.0\nText: Mean = 784.2217428817946, SD = 576.8946093859633, Median = 639.0\nText_Lemma_unlist: Mean = 192.45038826574634, SD = 145.56542397646643, Median = 156.0\nTime period: 1991 - 2008\nNumber.of.Forward.Citations: Mean = 18.405010056683125, SD = 41.724685977251376, Median = 7.0\nText: Mean = 914.8473212653136, SD = 625.5536198877876, Median = 760.0\nText_Lemma_unlist: Mean = 223.98180654598647, SD = 159.91728666283583, Median = 183.0\nTime period: 2009 - 2016\nNumber.of.Forward.Citations: Mean = 8.859221705863025, SD = 40.037448908277085, Median = 2.0\nText: Mean = 898.7358587992302, SD = 528.5306125716663, Median = 789.0\nText_Lemma_unlist: Mean = 229.06299582218466, SD = 144.08343556126138, Median = 197.0\nTime period: 2017 - 2023.0\nNumber.of.Forward.Citations: Mean = 1.6194664073400702, SD = 11.400910904718918, Median = 0.0\nText: Mean = 970.2785928713373, SD = 602.6431131549148, Median = 826.0\nText_Lemma_unlist: Mean = 247.44505517737093, SD = 164.30904354497343, Median = 205.0\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ntime_periods = [(min(df['Year']), 1990), (1991, 2008), (2009, 2016), (2017, max(df['Year']))]\n\nfor start, stop in time_periods:\n    df = pd.read_csv(f'/kaggle/input/cluster-dict/cluster_dict{start}_{stop}.csv')\n    all_word_pairs = pd.read_csv(f'/kaggle/input/tfidf-dummy/tfidf_dummy_{start}_{stop}_maxdf0.5_tfidfperc99.csv').drop('Unnamed: 0', axis=1).columns\n    # Get the column of lists\n    list_column = df.iloc[:, 1]\n\n    # Concatenate the lists\n    concatenated_list = []\n    for row in list_column:\n        # Remove the square brackets, split the string into a list, and remove the quotes around each element\n        row_list = [item.strip(\"'\\\"\") for item in row.strip('[]').split(', ')]\n        concatenated_list.extend(row_list)\n\n    n_word_pairs_in_clusters = len(concatenated_list)\n    print(f'{start}-{stop}')\n    print(f'Word Pairs in clusters: {n_word_pairs_in_clusters}')\n    print(f'Single variable Word Pairs: {len(all_word_pairs)-n_word_pairs_in_clusters}')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:21:26.640200Z","iopub.execute_input":"2024-05-13T10:21:26.640547Z","iopub.status.idle":"2024-05-13T10:23:32.288103Z","shell.execute_reply.started":"2024-05-13T10:21:26.640521Z","shell.execute_reply":"2024-05-13T10:23:32.283041Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"1920.0-1990\nWord Pairs in clusters: 170\nSingle variable Word Pairs: 37\n1991-2008\nWord Pairs in clusters: 3478\nSingle variable Word Pairs: 560\n2009-2016\nWord Pairs in clusters: 6693\nSingle variable Word Pairs: 1769\n2017-2023.0\nWord Pairs in clusters: 7796\nSingle variable Word Pairs: 2308\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\ntime_periods = [(min(df['Year']), 1990), (1991, 2008), (2009, 2016), (2017, max(df['Year']))]\n\nfor start, stop in time_periods:\n    cluster_dict = pd.read_csv(f'/kaggle/input/cluster-dict/cluster_dict{start}_{stop}.csv')\n    all_word_pairs = pd.read_csv(f'/kaggle/input/tfidf-dummy/tfidf_dummy_{start}_{stop}_maxdf0.5_tfidfperc99.csv').drop('Unnamed: 0', axis=1).columns\n    # Get the column of lists\n    list_column = cluster_dict.iloc[:, 1]\n\n    # Concatenate the lists\n    concatenated_list = []\n    for row in list_column:\n        # Remove the square brackets, split the string into a list, and remove the quotes around each element\n        row_list = [item.strip(\"'\\\"\") for item in row.strip('[]').split(', ')]\n        concatenated_list.extend(row_list)\n\n    n_word_pairs_in_clusters = len(concatenated_list)\n    n_single_variable_word_pairs = len(all_word_pairs) - n_word_pairs_in_clusters\n\n    print(f'{start}-{stop}')\n    print(f'Word Pairs in clusters: {n_word_pairs_in_clusters}')\n    print(f'Single variable Word Pairs: {n_single_variable_word_pairs}')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:42:03.841204Z","iopub.execute_input":"2024-05-13T10:42:03.841630Z","iopub.status.idle":"2024-05-13T10:43:51.227049Z","shell.execute_reply.started":"2024-05-13T10:42:03.841576Z","shell.execute_reply":"2024-05-13T10:43:51.225658Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"1920.0-1990\nWord Pairs in clusters: 170\nSingle variable Word Pairs: 37\n1991-2008\nWord Pairs in clusters: 3478\nSingle variable Word Pairs: 560\n2009-2016\nWord Pairs in clusters: 6693\nSingle variable Word Pairs: 1769\n2017-2023.0\nWord Pairs in clusters: 7796\nSingle variable Word Pairs: 2308\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\ntime_periods = [(min(df['Year']), 1990), (1991, 2008), (2009, 2016), (2017, max(df['Year']))]\n\n# Initialize a list to store the sets of all_word_pairs for each timeframe\nall_word_pairs_list = []\n\nfor start, stop in time_periods:\n    all_word_pairs = set(pd.read_csv(f'/kaggle/input/tfidf-dummy/tfidf_dummy_{start}_{stop}_maxdf0.5_tfidfperc99.csv').drop('Unnamed: 0', axis=1).columns)\n    all_word_pairs_list.append(all_word_pairs)\n\n# Check pairwise intersections\nfor i in range(len(time_periods)):\n    for j in range(i+1, len(time_periods)):\n        intersection = all_word_pairs_list[i].intersection(all_word_pairs_list[j])\n        print(f'Intersection between {time_periods[i]} and {time_periods[j]}: {len(intersection)}')\n\n# Check overall intersection\noverall_intersection = set.intersection(*all_word_pairs_list)\nprint(f'Overall intersection: {len(overall_intersection)}')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:43:51.229383Z","iopub.execute_input":"2024-05-13T10:43:51.229835Z","iopub.status.idle":"2024-05-13T10:45:30.094200Z","shell.execute_reply.started":"2024-05-13T10:43:51.229805Z","shell.execute_reply":"2024-05-13T10:45:30.092810Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Intersection between (1920.0, 1990) and (1991, 2008): 19\nIntersection between (1920.0, 1990) and (2009, 2016): 12\nIntersection between (1920.0, 1990) and (2017, 2023.0): 9\nIntersection between (1991, 2008) and (2009, 2016): 379\nIntersection between (1991, 2008) and (2017, 2023.0): 264\nIntersection between (2009, 2016) and (2017, 2023.0): 859\nOverall intersection: 4\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\ntime_periods = [(min(df['Year']), 1990), (1991, 2008), (2009, 2016), (2017, max(df['Year']))]\n\n# Initialize a list to store the sets of all_word_pairs for each timeframe\nall_word_pairs_list = []\ntotal_word_pairs = set()\n\nfor start, stop in time_periods:\n    all_word_pairs = set(pd.read_csv(f'/kaggle/input/tfidf-dummy/tfidf_dummy_{start}_{stop}_maxdf0.5_tfidfperc99.csv').drop('Unnamed: 0', axis=1).columns)\n    all_word_pairs_list.append(all_word_pairs)\n    total_word_pairs.update(all_word_pairs)\n\ntotal_unique_word_pairs = len(total_word_pairs)\n\nfor i in range(len(time_periods)):\n    for j in range(i+1, len(time_periods)):\n        intersection = all_word_pairs_list[i].intersection(all_word_pairs_list[j])\n        total_word_pairs = len(all_word_pairs_list[i]) + len(all_word_pairs_list[j])\n        print(f'Proportion of intersection between {time_periods[i]} and {time_periods[j]}: {len(intersection) / total_word_pairs:.2f}')\n# Check overall intersection\noverall_intersection = set.intersection(*all_word_pairs_list)\nprint(f'Proportion of overall intersection: {len(overall_intersection) / total_unique_word_pairs:.2f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:59:38.739474Z","iopub.execute_input":"2024-05-13T10:59:38.739927Z","iopub.status.idle":"2024-05-13T11:01:17.710796Z","shell.execute_reply.started":"2024-05-13T10:59:38.739898Z","shell.execute_reply":"2024-05-13T11:01:17.709214Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Proportion of intersection between (1920.0, 1990) and (1991, 2008): 0.00\nProportion of intersection between (1920.0, 1990) and (2009, 2016): 0.00\nProportion of intersection between (1920.0, 1990) and (2017, 2023.0): 0.00\nProportion of intersection between (1991, 2008) and (2009, 2016): 0.03\nProportion of intersection between (1991, 2008) and (2017, 2023.0): 0.02\nProportion of intersection between (2009, 2016) and (2017, 2023.0): 0.05\nProportion of overall intersection: 0.00018654976214905325\n","output_type":"stream"}]}]}