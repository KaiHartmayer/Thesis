{"metadata":{"colab":{"provenance":[],"name":"copy of borutashap-kaggle, incl. get_tfidf_dummy"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7945630,"sourceType":"datasetVersion","datasetId":4671976},{"sourceId":8118178,"sourceType":"datasetVersion","datasetId":4796642},{"sourceId":8118315,"sourceType":"datasetVersion","datasetId":4796733},{"sourceId":8118422,"sourceType":"datasetVersion","datasetId":4796819}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import random\nimport numpy as np\nimport pandas as pd\nimport tracemalloc\ntracemalloc.start()\nrandom.seed(3311791)\nnp.random.seed(3311791)\ndf = pd.read_csv('/kaggle/input/df-lemma-clean/df_lemma_dropped.csv').drop('H', axis=1)\ndf['Year'] = df['Year'].astype(int)","metadata":{"id":"xOvxpDP3E_Tx","execution":{"iopub.status.busy":"2024-05-12T11:49:33.147113Z","iopub.execute_input":"2024-05-12T11:49:33.148163Z","iopub.status.idle":"2024-05-12T11:49:46.40077Z","shell.execute_reply.started":"2024-05-12T11:49:33.148062Z","shell.execute_reply":"2024-05-12T11:49:46.398315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install umap-learn hdbscan\n!pip install BorutaShap\n!pip install xlsxwriter\n!pip install adjustText\nfrom adjustText import adjust_text\nfrom BorutaShap import BorutaShap\nimport umap\nimport hdbscan\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"id":"FGrS_sl2tSqs","outputId":"be1dc968-d731-4ac4-f26a-3d5e4eb5e1f7","execution":{"iopub.status.busy":"2024-05-12T11:49:46.558418Z","iopub.execute_input":"2024-05-12T11:49:46.560325Z","iopub.status.idle":"2024-05-12T11:50:48.438111Z","shell.execute_reply.started":"2024-05-12T11:49:46.560245Z","shell.execute_reply":"2024-05-12T11:50:48.43521Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Requirement already satisfied: umap-learn in /opt/conda/lib/python3.10/site-packages (0.5.5)\nRequirement already satisfied: hdbscan in /opt/conda/lib/python3.10/site-packages (0.8.33)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from umap-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from umap-learn) (1.11.4)\nRequirement already satisfied: scikit-learn>=0.22 in /opt/conda/lib/python3.10/site-packages (from umap-learn) (1.2.2)\nRequirement already satisfied: numba>=0.51.2 in /opt/conda/lib/python3.10/site-packages (from umap-learn) (0.58.1)\nRequirement already satisfied: pynndescent>=0.5 in /opt/conda/lib/python3.10/site-packages (from umap-learn) (0.5.12)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from umap-learn) (4.66.1)\nRequirement already satisfied: cython<3,>=0.27 in /opt/conda/lib/python3.10/site-packages (from hdbscan) (0.29.37)\nRequirement already satisfied: joblib>=1.0 in /opt/conda/lib/python3.10/site-packages (from hdbscan) (1.3.2)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.2->umap-learn) (0.41.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22->umap-learn) (3.2.0)\nRequirement already satisfied: BorutaShap in /opt/conda/lib/python3.10/site-packages (1.0.17)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from BorutaShap) (1.2.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from BorutaShap) (4.66.1)\nRequirement already satisfied: statsmodels in /opt/conda/lib/python3.10/site-packages (from BorutaShap) (0.14.1)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from BorutaShap) (3.7.5)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from BorutaShap) (2.2.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from BorutaShap) (1.26.4)\nRequirement already satisfied: shap>=0.34.0 in /opt/conda/lib/python3.10/site-packages (from BorutaShap) (0.44.1)\nRequirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (from BorutaShap) (0.12.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from BorutaShap) (1.11.4)\nRequirement already satisfied: packaging>20.9 in /opt/conda/lib/python3.10/site-packages (from shap>=0.34.0->BorutaShap) (21.3)\nRequirement already satisfied: slicer==0.0.7 in /opt/conda/lib/python3.10/site-packages (from shap>=0.34.0->BorutaShap) (0.0.7)\nRequirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from shap>=0.34.0->BorutaShap) (0.58.1)\nRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from shap>=0.34.0->BorutaShap) (2.2.1)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->BorutaShap) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->BorutaShap) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->BorutaShap) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->BorutaShap) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->BorutaShap) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->BorutaShap) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->BorutaShap) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->BorutaShap) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->BorutaShap) (2023.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->BorutaShap) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->BorutaShap) (3.2.0)\nRequirement already satisfied: patsy>=0.5.4 in /opt/conda/lib/python3.10/site-packages (from statsmodels->BorutaShap) (0.5.6)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from patsy>=0.5.4->statsmodels->BorutaShap) (1.16.0)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->shap>=0.34.0->BorutaShap) (0.41.1)\nRequirement already satisfied: xlsxwriter in /opt/conda/lib/python3.10/site-packages (3.2.0)\nRequirement already satisfied: adjustText in /opt/conda/lib/python3.10/site-packages (1.1.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from adjustText) (1.26.4)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from adjustText) (3.7.5)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from adjustText) (1.11.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->adjustText) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->adjustText) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->adjustText) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->adjustText) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->adjustText) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->adjustText) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->adjustText) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->adjustText) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->adjustText) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom scipy.sparse import lil_matrix, csr_matrix\nfrom itertools import combinations\nfrom collections import defaultdict\n\ntime_periods = [(min(df['Year']), 1990), (1991, 2008), (2009, 2016), (2017, max(df['Year']))]\n\ndf['Family.Number'] = df['Family.Number'].astype(str)\n\ndef get_tfidf_dummy(patent_df, max_df=0.95, tfidf_threshold_percentile=50, min_patent_cooc=2, max_feat=None, ngrams=(1,3)):\n    '''\n    tfidf_threshold = percentile of non-zero entries to be considered for co-occurrence analysis\n    min_patent_cooc = how often word combinations need to occur in different patents to be considered for further analysis (min_df=2 already in TFIDF)\n    '''\n    tfidf_vectorizer = TfidfVectorizer(ngram_range=ngrams,\n        max_df=max_df, min_df=2, stop_words=\"english\", max_features=max_feat)\n\n    tfidf = tfidf_vectorizer.fit_transform(patent_df['Text_Lemma_unlist'])\n    tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n\n    if tfidf_threshold_percentile is not None:\n        # percentile of nonzero entries in TF-IDF matrix\n        tfidf_threshold = np.percentile(tfidf.data, tfidf_threshold_percentile)\n        tfidf.data[tfidf.data < tfidf_threshold] = 0\n        tfidf.eliminate_zeros()\n        tfidf.data[tfidf.data >= tfidf_threshold] = 1\n    else:\n        tfidf.data[tfidf.data > 0] = 1\n        tfidf.eliminate_zeros()\n\n        \n    print(f'full len(tfidf_feature_names): {len(tfidf_feature_names)}')\n    # Find columns which have at least 2 times a 1 in them\n    cols_to_keep = [i for i in range(tfidf.shape[1]) if len(tfidf[:, i].data) >= min_patent_cooc]\n    tfidf = tfidf[:, cols_to_keep]\n\n    # Also keep the corresponding feature names\n    tfidf_feature_names = [tfidf_feature_names[i] for i in cols_to_keep]\n    print(f'trimmed len(tfidf_feature_names): {len(tfidf_feature_names)}')\n\n    # Initialize the storage container\n    tfidf_dummy = lil_matrix((tfidf.shape[0], len(tfidf_feature_names)*(len(tfidf_feature_names)-1)//2))\n    column_dict = defaultdict(lambda: len(column_dict))\n    for name in tfidf_feature_names:\n        column_dict[name]\n    # Iterate over each row in the tfidf matrix\n    #indices = [i for i in range(tfidf.shape[0]) if i not in range(10900, 11500)]\n    for index in range(tfidf.shape[0]):\n        row = tfidf.getrow(index)\n        # Get all combinations of feature names for the current row\n\n        pairs = combinations([tfidf_feature_names[i] for i in row.indices], 2)\n\n        for pair in pairs:\n            # Check if neither feature name is a substring of the other\n            if not (pair[0] in pair[1] or pair[1] in pair[0]):\n                # Sort the pair and convert to a tuple\n                sorted_pair = tuple(sorted(pair))\n                # Generate a column name from the sorted pair\n                column_name = '+'.join(sorted_pair)\n                # If the column doesn't exist yet, add it to the dictionary\n                if column_name not in column_dict:\n                    column_dict[column_name] = len(column_dict)\n                # Add a 1 for this entry in the tfidf_dummy container\n                tfidf_dummy[index, column_dict[column_name]] = 1\n\n    col_sums = np.array(tfidf_dummy.sum(axis=0)).ravel() # tfidf_dummy.sum(axis=0) #\n\n    print(f'N word pairs in {min(patent_df[\"Year\"])}-{max(patent_df[\"Year\"])}: {len(col_sums)}')\n    cols_to_retain = np.where(col_sums >= min_patent_cooc)[0]\n    print(f'N columns to retain in {min(patent_df[\"Year\"])}-{max(patent_df[\"Year\"])} when filtering out co-occurrences in less than {min_patent_cooc} patents: {len(cols_to_retain)}')\n\n    tfidf_dummy = tfidf_dummy[:, cols_to_retain]\n\n    return  pd.DataFrame(tfidf_dummy.toarray(), columns=[name for name, index in column_dict.items() if index in cols_to_retain])\n\n\nfor i, (start, stop) in enumerate(time_periods):\n        df_time_period = df[(df['Year'] >= start) & (df['Year'] <= stop)]\n        print(f'{start}-{stop}')\n        max_df=0.5; max_feat=None; tfidf_threshold_percentile=99; n_components=2; n_try=1; min_patent_cooc=2\n\n        tfidf_dummy = get_tfidf_dummy(df_time_period, max_df=max_df, max_feat=max_feat, min_patent_cooc=min_patent_cooc, tfidf_threshold_percentile=tfidf_threshold_percentile)\n        tfidf_dummy.to_csv(f'tfidf_dummy_{start}_{stop}_maxdf{max_df}_tfidfperc{tfidf_threshold_percentile}.csv')","metadata":{"execution":{"iopub.status.busy":"2024-05-12T11:50:48.664664Z","iopub.execute_input":"2024-05-12T11:50:48.665519Z","iopub.status.idle":"2024-05-12T12:57:07.29924Z","shell.execute_reply.started":"2024-05-12T11:50:48.665421Z","shell.execute_reply":"2024-05-12T12:57:07.296759Z"},"id":"rWI1nb9z-jGT","outputId":"482110e4-1546-49c6-8707-58c4af98e267","trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"1991-2008\nfull len(tfidf_feature_names): 379563\ntrimmed len(tfidf_feature_names): 3960\nN word pairs in 1991-2008: 7838820\nN columns to retain in 1991-2008 when filtering out co-occurrences in less than 2 patents: 4038\n1920-1990\nfull len(tfidf_feature_names): 53341\ntrimmed len(tfidf_feature_names): 456\nN word pairs in 1920-1990: 103740\nN columns to retain in 1920-1990 when filtering out co-occurrences in less than 2 patents: 207\n2009-2016\nfull len(tfidf_feature_names): 738115\ntrimmed len(tfidf_feature_names): 7642\nN word pairs in 2009-2016: 29196261\nN columns to retain in 2009-2016 when filtering out co-occurrences in less than 2 patents: 8462\n2017-2023\nfull len(tfidf_feature_names): 825368\ntrimmed len(tfidf_feature_names): 8361\nN word pairs in 2017-2023: 34948980\nN columns to retain in 2017-2023 when filtering out co-occurrences in less than 2 patents: 10104\n","output_type":"stream"}]}]}